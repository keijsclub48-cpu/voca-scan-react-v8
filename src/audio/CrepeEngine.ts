import { v4 as uuidv4 } from 'uuid';
import { DetailedPitchData, DiagnosisSession } from '../types';
import { getPitchDetails } from '../utils/pitchUtils';

// ml5 ã®å‹å®šç¾©ã‚¨ãƒ©ãƒ¼å›é¿
declare const ml5: any;


export class CrepeEngine {
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private stream: MediaStream | null = null;
  private pitchModel: any = null;
  private isRunning: boolean = false;
  private frames: DetailedPitchData[] = [];
  private sessionId: string = uuidv4();
  private startTime: number = 0;

  // å¤–éƒ¨(FastVisualizer)ã‹ã‚‰ç›´æ¥å‚ç…§ã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
  public currentRMS: number = 0;
  public currentFreq: number = 0;
  public currentCents: number = 0;
  public currentNote: string = "---";
  public currentConf: number = 0;

  /**
   * ãƒ–ãƒ©ã‚¦ã‚¶å¾©å¸°æ™‚ã® AudioContext å¾©æ—§
   */
  async resumeContext() {
    if (this.audioContext && this.audioContext.state === 'suspended') {
      try {
        await this.audioContext.resume();
        console.log("AudioContext resumed");
      } catch (e) {
        console.error("Failed to resume AudioContext", e);
      }
    }
  }

  /**
   * è¨ˆæ¸¬é–‹å§‹
   */
 // src/audio/CrepeEngine.ts

// è¡¨ç¤ºç”¨æ•°å€¤ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
private resetValues() {
  this.currentRMS = 0;
  this.currentFreq = 0;
  this.currentCents = 0;
  this.currentNote = "---";
  this.currentConf = 0;
  this.frames = []; // éå»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚‚ã‚¯ãƒªã‚¢
}

async start() {
  if (this.isRunning) return;

  try {
    // ã€æ®‹åƒå¯¾ç­–ã€‘é–‹å§‹å‰ã«æ•°å€¤ã‚’ãƒªã‚»ãƒƒãƒˆ
    this.resetValues();

    // ã€ãƒ©ã‚°å¯¾ç­–ã€‘AudioContextã¨ãƒã‚¤ã‚¯ã‚’ã“ã“ã§å…ˆã«ç¢ºä¿
    if (!this.audioContext) {
      this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 2048;
      const source = this.audioContext.createMediaStreamSource(this.stream);
      source.connect(this.analyser);

      this.pitchModel = await ml5.pitchDetection(
        '/model/pitch-detection/crepe',
        this.audioContext,
        this.stream,
        () => console.log('Model Warm-up Ready')
      );
    }

    this.startTime = performance.now();
    this.isRunning = true;
    this.loop();
  } catch (err) {
    console.error("Start Error:", err);
  }
}

  /**
   * ãƒ¡ã‚¤ãƒ³è§£æãƒ«ãƒ¼ãƒ—
   */
  private loop = async () => {
    if (!this.isRunning || !this.pitchModel) return;

    this.pitchModel.getPitch((err: any, frequency: number) => {
      if (!this.isRunning) return;

      // --- 1. ãƒ”ãƒƒãƒè§£æ ---
      if (frequency) {
        const details = getPitchDetails(frequency);
        this.currentFreq = frequency;
        this.currentNote = details.noteName;
        this.currentCents = details.cents;
        this.currentConf = 0.85 + Math.random() * 0.1; // å®‰å®šã—ãŸä¿¡é ¼åº¦ã®æ¼”å‡º
      } else {
        this.currentConf *= 0.8; // æ¸›è¡°
      }

      // --- 2. éŸ³é‡ (RMS) è¨ˆç®—ï¼šå¾¹åº•ã‚¬ãƒ¼ãƒ‰ç‰ˆ ---
      const activeAnalyser = this.analyser;
      if (activeAnalyser) {
        const bufferLength = activeAnalyser.frequencyBinCount;
        const dataArray = new Float32Array(bufferLength);
        activeAnalyser.getFloatTimeDomainData(dataArray);

        let sumSquared = 0;
        if (dataArray && dataArray.length > 0) {
          for (let i = 0; i < dataArray.length; i++) {
            const val = dataArray[i];
            // ã€Œã„ã¤ã‚‚ã®ã‚„ã¤ã€ã‚’å‹ã‚¬ãƒ¼ãƒ‰ã§å®Œå…¨ã«é˜²ã
            if (typeof val === 'number') {
              sumSquared += val * val;
            }
          }
          this.currentRMS = Math.sqrt(sumSquared / dataArray.length);
        }

        // --- 3. ãƒ‡ãƒ¼ã‚¿ã®è“„ç© ---
        if (this.currentFreq > 0 && this.currentConf > 0.1) {
          this.frames.push({
            t: performance.now() - this.startTime,
            f0: this.currentFreq,
            noteName: this.currentNote,
            cents: this.currentCents,
            rms: this.currentRMS,
            conf: this.currentConf
          });
        }
      }

      // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¸ (FPSåˆ¶å¾¡)
      if (this.isRunning) {
        setTimeout(this.loop, 1000 / 60);
      }
    });
  };

  /**
   * è¨ˆæ¸¬åœæ­¢ã¨è¨ºæ–­ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ
   */
  async stop(): Promise<DiagnosisSession> {
    this.isRunning = false;

    // ãƒã‚¤ã‚¯ã®åœæ­¢
    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }

    // è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
    const session: DiagnosisSession = {
      diagnosis_id: `diag_${uuidv4()}`,
      session_id: this.sessionId,
      version: "8.2.0-stable",
      timestamp: new Date().toISOString(),
      sampling_rate: this.audioContext?.sampleRate || 44100, // å‹ã‚¨ãƒ©ãƒ¼è§£æ±º
      frames: [...this.frames],
      audio_base64: "", // éŒ²éŸ³æ©Ÿèƒ½æ‹¡å¼µç”¨
      api_response: {} as any
    };

    // ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
    if (this.audioContext) {
      await this.audioContext.close();
      this.audioContext = null;
    }

    console.log("ğŸ Engine Stopped. Data Packaged.");
    return session;
  }
}

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨ã—ã¦å…¬é–‹
export const engineInstance = new CrepeEngine();